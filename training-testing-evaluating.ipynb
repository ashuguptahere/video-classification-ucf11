{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing Essential Libraries\nimport os\nimport glob\nimport time\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger, EarlyStopping\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Required Parameters\ntrain_path = \"/kaggle/input/video-classification-ucf11/testing_set/\"            # Training Path\ntest_path = \"/kaggle/input/video-classification-ucf11/testing_set/\"             # Testing Path\nno_of_frames = 1650                                                             # Number of Frames\nch = 4                                                                          # Model Selection Choice\nepochs = 20                                                                     # Number of epochs\nbatch_size = 32                                                                 # Batch Size\nn_classes = 11                                                                  # Number of Classes\npatience = 2                                                                    # Patience for EarlyStopping\nstime = int(time.time())                                                        # Defining Starting Time\ncategories = os.listdir(train_path)                                             # Name of each Class/Category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories.sort()\nprint(categories)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining Base Model according to choice given\n# By default Model 4 [ResNet50V2] is selected\nif ch == 1:\n    from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n    base_model = ResNet50(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 2:\n    from tensorflow.keras.applications.resnet import ResNet101, preprocess_input\n    base_model = ResNet101(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 3:\n    from tensorflow.keras.applications.resnet import ResNet152, preprocess_input\n    base_model = ResNet150(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 4:\n    from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n    base_model = ResNet50V2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 5:\n    from tensorflow.keras.applications.resnet_v2 import ResNet101V2, preprocess_input\n    base_model = ResNet101V2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 6:\n    from tensorflow.keras.applications.resnet_v2 import ResNet152V2, preprocess_input\n    base_model = ResNet150V2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 7:\n    from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n    base_model = MobileNet(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\nelif ch == 8:\n    from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n    base_model = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation = 'relu')(x)\nx = Dropout(0.5)(x)\n# x = Dense(512, activation = 'relu')(x)\n# x = Dense(256, activation = 'relu')(x)\npreds = Dense(n_classes, activation = 'softmax')(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(inputs = base_model.input, outputs = preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing the names of each layer\nfor i, layer in enumerate(model.layers):\n    print(i, layer.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Summary\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting each layer as trainable\nfor layer in model.layers:\n    layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting 1/3 layers as trainable\n# for layer in model.layers[:65]:\n#     layer.trainable = False\n# for layer in model.layers[65:]:\n#     layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining Image Data Generators\ntrain_datagenerator = ImageDataGenerator(preprocessing_function = preprocess_input,\n                                         validation_split = 0.2)\n\ntest_datagenerator = ImageDataGenerator(preprocessing_function = preprocess_input)\n\ntrain_generator = train_datagenerator.flow_from_directory(train_path,\n                                                          target_size = (224, 224),\n                                                          color_mode = 'rgb',\n                                                          batch_size = batch_size,\n                                                          class_mode = 'categorical',\n                                                          shuffle = True)\n\nvalidation_generator = train_datagenerator.flow_from_directory(train_path,\n                                                               target_size = (224, 224),\n                                                               color_mode = 'rgb',\n                                                               batch_size = batch_size,\n                                                               class_mode = 'categorical',\n                                                               subset = 'validation')\n\ntest_generator = test_datagenerator.flow_from_directory(test_path,\n                                                        target_size = (224, 224),\n                                                        color_mode = 'rgb',\n                                                        class_mode = 'categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_generator.class_indices)\nprint(validation_generator.class_indices)\nprint(test_generator.class_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compiling the Model\nmodel.compile(optimizer = \"Adam\",\n              loss = \"categorical_crossentropy\",\n              metrics = [\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a timestamp directory\ntry:\n    os.mkdir(\"{}_{}b_{}e\".format(stime, batch_size, epochs))\nexcept:\n    print(\"Directory already present...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CSVLogger\nfilename = \"{}_{}b_{}\\\\file.csv\".format(stime, batch_size, epochs)\ncsv_log = CSVLogger(filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Early Stopping\nearly_stopping = EarlyStopping(patience = patience)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tensorboard\ntensorboard = TensorBoard(log_dir = \"{}_{}b_{}e\\logs\".format(stime, batch_size, epochs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining Model Checkpoint\ncheckpoint_name = \"{}_{}b_{}e\".format(stime, batch_size, epochs)\ncheckpoint_path = checkpoint_name + \"\\cp-{epoch:04d}-{accuracy:.4f}a-{loss:.4f}l-{val_accuracy:.4f}va-{val_loss:.4f}vl.h5\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\nmodel_checkpoint = ModelCheckpoint(checkpoint_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the Model\nhistory = model.fit(train_generator,\n                    validation_data = validation_generator,\n                    epochs = epochs,\n                    callbacks = [model_checkpoint, tensorboard, csv_log, early_stopping])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the Graph\nmodel_history = pd.DataFrame(history.history)\nmodel_history.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Loading Model\n# from tensorflow.keras.models import load_model\n# model = load_model(r\"foldername/filename.h5\") # Enter your model here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating Model's Performance\nhistory2 = model.evaluate(test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Testing on testing_set/"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Loading Tensorflow.Keras Model\n# model = tf.keras.models.load_model(\"foldername/filename.h5\") # Enter your model here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image Data Generator\ntest_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n\ntest_generator = test_datagen.flow_from_directory(test_path,\n                                                  target_size = (224, 224),\n                                                  color_mode = \"rgb\",\n                                                  shuffle = False,\n                                                  class_mode = 'categorical',\n                                                  batch_size = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"activities = test_generator.class_indices\nprint(activities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_activity(val):\n    for key, value in activities.items():\n        if val == value:\n            return key\n    return \"Invalid\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = test_generator.filenames\nnb_samples = len(filenames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict(test_generator, steps = nb_samples, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = []\nfor val in predict:\n    y_pred.append(get_activity(np.argmax(val)))\n\ny_true = []\nfor file in filenames:\n    y_true.append(file.split(\"\\\\\")[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_true, y_pred)\n\nprint(precision_score(y_true, y_pred, average = 'macro'))\nprint(recall_score(y_true, y_pred, average = 'macro'))\nprint(f1_score(y_true, y_pred, average = 'macro'))\n\nprint(precision_score(y_true, y_pred, average = 'micro'))\nprint(recall_score(y_true, y_pred, average = 'micro'))\nprint(f1_score(y_true, y_pred, average = 'micro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making a Classification Report\nprint(classification_report(y_true, y_pred))\n\ndataframe = pd.DataFrame(cm)\ninv_dict = {v: k for k, v in activities.items()} \ndataframe = dataframe.rename(index = inv_dict)\ndataframe = dataframe.rename(columns = inv_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving Confusion Matrix in CSV format\ndataframe.to_csv(\"Perfomance Confusion Matrix.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}